{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vFXgflvZ6Ga"
   },
   "source": [
    "## Assignment #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UevAU0CYVhiu"
   },
   "source": [
    "* Release date: 2021.04.12 Mon\n",
    "* Due date: **2021.04.18 Sun 23:59** (will not accept late submission)\n",
    "* Submission format: notebook file which can be executed in Colab environment\n",
    "* Weighting: 5% (total 50 pts)\n",
    "* You will build a multi-class classification model using Reuters dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxrhNNhWbfHD"
   },
   "source": [
    "> ### Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "8E-2WLHgcAit"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "# Like IMDB, the argument num_words restricts the data to \n",
    "# the 10,000 most frequently occurring words \n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding newswires back to text\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3EivNEoEKTF"
   },
   "source": [
    "* (10pts) Write the codes for preprocessing data\n",
    "  * For inputs, the data we have should be converted to binary vectors.\n",
    "  * For labels, determine an appropriate format by referring to the arguments of model.compile function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "yrjD9AerdW4X"
   },
   "outputs": [],
   "source": [
    "# write preprocessing codes\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "    \n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# one_hot_train_labels = to_categorical(train_labels)\n",
    "# one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgUJiPeicE"
   },
   "source": [
    "> ### Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "Edwc4GbneqKA"
   },
   "outputs": [],
   "source": [
    "# Do not modify this block\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "hxGWsKkdgAnq"
   },
   "outputs": [],
   "source": [
    "# Do not modify this block\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0TUwiHLgI_-"
   },
   "source": [
    "> ### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFe4FOkfgUII"
   },
   "source": [
    "* We employ *k-fold cross validation* as validation method of our model.\n",
    "* **(15pts)** Write a code in the below to perform *10-fold cross validation*.\n",
    "* **For each fold, save a model at every epoch in your Google Drive.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 0s 41us/sample - loss: 0.1076 - accuracy: 0.9578\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 36us/sample - loss: 0.1034 - accuracy: 0.9592\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s 34us/sample - loss: 0.1064 - accuracy: 0.9590\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 0s 37us/sample - loss: 0.1039 - accuracy: 0.9572\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s 37us/sample - loss: 0.0999 - accuracy: 0.9577\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s 36us/sample - loss: 0.0978 - accuracy: 0.9578\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.1011 - accuracy: 0.9587\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0938 - accuracy: 0.9592\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0986 - accuracy: 0.9575\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0958 - accuracy: 0.9580\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0948 - accuracy: 0.9575\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0942 - accuracy: 0.9574\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0916 - accuracy: 0.9594\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0919 - accuracy: 0.9578\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s 36us/sample - loss: 0.0912 - accuracy: 0.9584\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s 37us/sample - loss: 0.0881 - accuracy: 0.9599\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s 37us/sample - loss: 0.0873 - accuracy: 0.9597\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s 36us/sample - loss: 0.0930 - accuracy: 0.9589\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s 35us/sample - loss: 0.0880 - accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s 31us/sample - loss: 0.0861 - accuracy: 0.9600\n",
      "2246/2246 [==============================] - 0s 89us/sample - loss: 1.5151 - accuracy: 0.7787\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512)\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "jPWjg2s4WYfm"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 'My Drive'/exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = '/content/gdrive/My Drive/exp/model.{epoch:02d}.hdf5'\n",
    "modelckpt = ModelCheckpoint(filepath=filepath)\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=9,\n",
    "          batch_size=512,\n",
    "          validation_data(x_val, y_val),\n",
    "          callbacks=[modelckpt])\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a code for 10-fold cross validation here\n",
    "\n",
    "k = 10\n",
    "num_validation_samples = len(x_test) // k\n",
    "\n",
    "np.random.shuffle(x_test)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "  validation_data = x_test[num_validation_samples*fold : num_validation_samples*(fold+1)]\n",
    "  training_data = x_test[:num_validation_samples*fold] + x_test[num_validation_samples*(fold+1):]\n",
    "\n",
    "  model = get_model()\n",
    "  model.train(training_data)\n",
    "  validation_score = model.evaluate(validation_data)\n",
    "  validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model = get_model()\n",
    "model.train(x_test)\n",
    "test_score = model.evaluate(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8908muCWdnG"
   },
   "source": [
    "* **(10pts)** Plotting the training and validation accuracy\n",
    "  * To obtain the validation accuracy at the end of every epoch, just average the performances of all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "6PJb3RyXXZlC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-37aa99c66493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# write a code for plotting the training and validation accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Traning and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS0D5_0iXd_y"
   },
   "source": [
    "> ### (15pts) Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9HNF524XkCy"
   },
   "source": [
    "* Find the best performance model by seeing the performance plot.\n",
    "* Calculate the accuracy on test set using the best performance model.\n",
    "  * Here, you should use a majority voting method to get the prediction for a test data point.\n",
    "  * Specifically, given a test data point, get the predicted class from the trained model on each fold, and then decide the final predicted class by a majority voting.\n",
    "* **Do not retrain the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhDWsnWuY5w-"
   },
   "outputs": [],
   "source": [
    "# write a code here"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment2.ipynb",
   "provenance": [
    {
     "file_id": "1-P7BRCDG61fz-Qh2iBU7vgOoYGumS7SP",
     "timestamp": 1554095812727
    }
   ]
  },
  "kernelspec": {
   "display_name": "tf21",
   "language": "python",
   "name": "tf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
