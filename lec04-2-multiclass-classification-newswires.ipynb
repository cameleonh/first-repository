{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lec04-2-multiclass-classification-newswires.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6vFXgflvZ6Ga"},"source":["## Classifying newswires: a multiclass classification example"]},{"cell_type":"markdown","metadata":{"id":"RwgAFvH3agAN"},"source":["* Now, we know how to classify vector inputs into two mutually exclusive classes using a densely connected neural networks.\n","* Here, we will build a network to classify Reuters newswires into 46 mutually exclusive topics.\n","* Since we have many classes, this problem is an instance of *multi-class classification*.\n","* *single-label, multiclass classification* VS *multilabel, multiclass classification*"]},{"cell_type":"markdown","metadata":{"id":"KxrhNNhWbfHD"},"source":["> ### The Reuters dataset"]},{"cell_type":"markdown","metadata":{"id":"gO8MwlRwblto"},"source":["* A set of short newswires and their topics, published by Reuters in 1986"]},{"cell_type":"code","metadata":{"id":"8E-2WLHgcAit"},"source":["from tensorflow.keras.datasets import reuters\n","\n","# Like IMDB, the argument num_words restricts the data to \n","# the 10,000 most frequently occurring words \n","(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnirpZNlcarg"},"source":["len(train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DkNrN8YcfkY"},"source":["len(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSl5-hKpcgji"},"source":["train_data[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcT1UyFocixb"},"source":["# decoding newswires back to text\n","word_index = reuters.get_word_index()\n","reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n","decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4C9PB-S2c6yF"},"source":["print(decoded_newswire)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1ufaj0_c9qF"},"source":["train_labels[10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaUKTzTEI93o"},"source":["train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7r5sOpsVJAyn"},"source":["len(train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1wkBo0UydPIE"},"source":["> ### Preparing the data"]},{"cell_type":"code","metadata":{"id":"yrjD9AerdW4X"},"source":["import numpy as np\n","\n","def vectorize_sequences(sequences, dimension=10000):\n","  results = np.zeros((len(sequences), dimension))\n","  for i, sequence in enumerate(sequences):\n","    results[i, sequence] = 1.\n","  return results\n","\n","x_train = vectorize_sequences(train_data)\n","x_test = vectorize_sequences(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DD_y97mydqee"},"source":["x_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JvxcZowAdr3c"},"source":["* To vectorize the labels, we can use one-hot encoding.\n","* One-hot encoding of the labels consists of embedding each label as an all-zero vector with a 1 in the place of the label index."]},{"cell_type":"code","metadata":{"id":"6L6LDw-peC_l"},"source":["def to_one_hot(labels, dimension=46):\n","  results = np.zeros((len(labels), dimension))\n","  for i, label in enumerate(labels):\n","    results[i, label] = 1.\n","  return results\n","\n","one_hot_train_labels = to_one_hot(train_labels)\n","one_hot_test_labels = to_one_hot(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RB9FA3NT-IvZ"},"source":["train_labels[100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzmn2BdK-K8_"},"source":["one_hot_train_labels[100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmLRa5GNeSOi"},"source":["from tensorflow.keras.utils import to_categorical\n","\n","one_hot_train_labels = to_categorical(train_labels)\n","one_hot_test_labels = to_categorical(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yWfgUJiPeicE"},"source":["> ### Building the network"]},{"cell_type":"code","metadata":{"id":"Edwc4GbneqKA"},"source":["from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(46, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Jh9veDSfJmP"},"source":["* `softmax` activation in the last layer\n","  * The network will ouput a *probability distribution* over the 46 classes.\n","  * For every input sample, the network will produce a 46-dimensional output vector, where `output[i]` is the probability that the sample belongs to class `i`.\n","  * The sum of `output[i]` for all `i` will be 1.\n","  \n","* `categorical_crossentropy` loss\n","  * It measures the distance between two probability distributions.\n","  * Here, between the probability distribution output by the network and the true distribution of the labels"]},{"cell_type":"code","metadata":{"id":"hxGWsKkdgAnq"},"source":["model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j0TUwiHLgI_-"},"source":["> ### Validation"]},{"cell_type":"markdown","metadata":{"id":"KFe4FOkfgUII"},"source":["* Use 1,000 samples in the training data as a validation set."]},{"cell_type":"code","metadata":{"id":"bYqC9csRgbq3"},"source":["x_val = x_train[:1000]\n","partial_x_train = x_train[1000:]\n","\n","y_val = one_hot_train_labels[:1000]\n","partial_y_train = one_hot_train_labels[1000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"msIJEuaZgmzs"},"source":["history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=20,\n","                    batch_size=512,\n","                    validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R_9qF3zbgu7c"},"source":["* Plotting the training and validation loss"]},{"cell_type":"code","metadata":{"id":"s6UxBwD_hAdL"},"source":["import matplotlib.pyplot as plt\n","\n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(loss) + 1)\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') \n","plt.plot(epochs, val_loss, 'b', label='Validation loss') \n","plt.title('Training and validation loss') \n","plt.xlabel('Epochs') \n","plt.ylabel('Loss') \n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6rfRKHaNhGEl"},"source":["* Plotting the training and validation accuracy"]},{"cell_type":"code","metadata":{"id":"LrpLWsPchK2s"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rxkKZvn2hc9Y"},"source":["* We can observe that the network begins to overfit after nine epochs.\n","* Retraining a model from scratch"]},{"cell_type":"code","metadata":{"id":"fxsZ5wvbioQw"},"source":["model.fit(partial_x_train, \n","          partial_y_train, \n","          epochs=9, \n","          batch_size=512, \n","          validation_data=(x_val, y_val)) \n","\n","results = model.evaluate(x_test, one_hot_test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"88XEzF6_izB4"},"source":["print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccHWQKBDi16d"},"source":["* Retraining a model from scratch is not a good idea if we have a large-scale training set.\n","* In this case, we can use `callbacks` functionality in `keras`.\n","  * https://keras.io/callbacks/\n","  \n","* Before, we need to mount Google Drive storage with our colab instance."]},{"cell_type":"code","metadata":{"id":"ojK8WqoikxmE"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCxC7fEkDwfS"},"source":["%cd /content/gdrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRaLNWqgEC9v"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGHLJeA7EM5B"},"source":["%cd 'My Drive'/exp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wO6i-R9pjiyw"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","filepath = '/content/gdrive/My Drive/exp/model.{epoch:02d}.hdf5'\n","modelckpt = ModelCheckpoint(filepath=filepath)\n","\n","model.fit(partial_x_train, \n","          partial_y_train, \n","          epochs=20, \n","          batch_size=512, \n","          validation_data=(x_val, y_val),\n","          callbacks=[modelckpt]) \n","\n","results = model.evaluate(x_test, one_hot_test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JmW5B11UnNkW"},"source":["* Load the trained model at epoch 9"]},{"cell_type":"code","metadata":{"id":"E9Li2aSOrMT_"},"source":["best_model_path = '/content/gdrive/My Drive/exp/model.09.hdf5'\n","best_model = models.load_model(best_model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMi79IsCrcJN"},"source":["results = best_model.evaluate(x_test, one_hot_test_labels)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5DhiOIWprjmc"},"source":["> ### Generating predictions on new data"]},{"cell_type":"code","metadata":{"id":"E_YOCXMvsJTD"},"source":["predictions = model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kb5PgSnIOJVO"},"source":["predictions.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHUAgixMsNAa"},"source":["predictions[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fx3_mWNsOvt"},"source":["np.sum(predictions[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2orsx3RsQKF"},"source":["np.argmax(predictions[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9OFtIzqsR5k"},"source":["> ### A different way to handle the labels and the loss"]},{"cell_type":"code","metadata":{"id":"HOshl7cHsj4H"},"source":["y_train = np.array(train_labels)\n","y_test = np.array(test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5Oo6KEmso67"},"source":["model.compile(optimizer='rmsprop',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['acc'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ckhrm_RIsv4n"},"source":["> ### The importance of having sufficiently large hidden layers"]},{"cell_type":"code","metadata":{"id":"A9X9G8PWtFKf"},"source":["model = models.Sequential()\n","model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n","model.add(layers.Dense(4, activation='relu'))\n","model.add(layers.Dense(46, activation='softmax'))\n","\n","model.compile(optimizer='rmsprop',\n","               loss='categorical_crossentropy',\n","               metrics=['accuracy'])\n","\n","model.fit(partial_x_train,\n","          partial_y_train,\n","          epochs=20,\n","          batch_size=128,\n","          validation_data=(x_val, y_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpTkfxhTHhVz"},"source":[""],"execution_count":null,"outputs":[]}]}